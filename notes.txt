# AICAI - Architecture & Functionality Notes

**Author:** Gemini (Senior Open-Source Engineer)
**Purpose:** Internal planning document for the AICAI project. This file details the architecture, functionality, and design rationale to ensure an efficient and effective implementation.

---

## 1. Project Goal & Core Philosophy

**Goal:** Create a CLI tool that uses small, fast LLMs (via Groq) to recursively generate and improve code, inspired by the ASI-Arch project.

**Philosophy:**
- **Efficiency-First:** Every component must be lean and essential. No feature creep.
- **Recursive Improvement:** The core value comes from the iterative loop, not a single powerful model.
- **Small Model Optimization:** The entire system must be designed to work around the constraints of an ~8K token context window.

---

## 2. Detailed Architecture (V1 - Deprecated)

(Previous architecture notes are deprecated in favor of the V3 Deep Dive)

---

## 3. Architectural Deep Dive - V3

**Research Synthesis:** My previous models were too simplistic. True autonomous systems require a clear separation of concerns between the controller (the orchestrator), the state (the memory), and the specialized functions (the personas). The architecture needs to be modeled as a **State Machine** governed by an **Orchestrator**, operating on a well-defined **Working Memory**. This is the key to enabling complex, emergent behavior from simple, stateless LLM calls.

### 3.1. The Working Memory (The System's State)

This is no longer an abstract concept. It will be implemented as a concrete Python dataclass. This provides structure and type safety.

```python
@dataclass
class WorkingMemory:
    user_goal: str
    code_state: Dict[str, str]  # {filepath: content}
    plan: List[Dict]  # e.g., {'id': 1, 'task': '...', 'status': 'pending'}
    execution_trace: List[str]
    critique: List[Dict] # e.g., {'type': 'BUG', 'details': '...'}
    iteration: int
```

-   **Why this structure?** It forces a rigorous, machine-readable representation of the system's state. The `plan` and `critique` are no longer freeform text but structured data. This allows the Orchestrator to make decisions based on data, not by parsing prose.

### 3.2. The Orchestrator (The State Machine)

The `recursive_improver.py` will implement the Orchestrator. Its core is a `run()` method that acts as a state machine loop.

**States:** `[PLANNING, CODING, REVIEWING, CORRECTING, FINALIZING]`

1.  **`PLANNING` State:**
    -   **Trigger:** First iteration, or when the `CORRECTING` state determines the plan is flawed.
    -   **Action:** Calls the `Architect` persona.
    -   **Input to LLM:** `working_memory.user_goal`, `working_memory.critique`.
    -   **Output from LLM:** A JSON object representing the plan.
    -   **State Update:** `working_memory.plan` is overwritten. `working_memory.critique` is cleared.
    -   **Next State:** `CODING`.

2.  **`CODING` State:**
    -   **Trigger:** The `plan` has tasks with `status: 'pending'`.
    -   **Action:** Loops through pending tasks and calls the `Coder` persona for each.
    -   **Input to LLM:** `working_memory.code_state`, and a *single* task from `working_memory.plan`.
    -   **Output from LLM:** A code snippet or modification (e.g., a diff).
    -   **State Update:** The Orchestrator applies the change to `working_memory.code_state`. The task's status in `working_memory.plan` is updated to `'done'`.
    -   **Next State:** `REVIEWING` (once a batch of coding tasks is complete).

3.  **`REVIEWING` State:**
    -   **Trigger:** After a `CODING` cycle.
    -   **Action:** Calls the `Reviewer` persona.
    -   **Input to LLM:** `working_memory.code_state`, `working_memory.plan`.
    -   **Output from LLM:** A JSON array of critique objects.
    -   **State Update:** `working_memory.critique` is populated with the output.
    -   **Next State:** `CORRECTING`.

4.  **`CORRECTING` State:**
    -   **Trigger:** After a `REVIEWING` cycle.
    -   **Action:** This is a pure logic step, no LLM call. It's the "decision maker."
    -   **Logic:**
        -   If `working_memory.critique` is empty, transition to `FINALIZING`.
        -   If critique contains high-level issues (e.g., architectural flaws), transition to `PLANNING`.
        -   If critique contains simple bugs, it modifies the `plan`, adding new tasks (e.g., `{'task': 'Fix bug in function X', 'status': 'pending'}`). Then transitions to `CODING`.
    -   **Next State:** `PLANNING`, `CODING`, or `FINALIZING`.

5.  **`FINALIZING` State:**
    -   **Trigger:** The `CORRECTING` state finds no more issues.
    -   **Action:** The loop terminates. The final code is presented to the user.

### 3.3. Why This Architecture Excels with Small Models

-   **Extreme Task Decomposition:** The LLM is never asked to do more than one, tiny thing at a time. The `Coder` implements one function. The `Architect` creates one plan. This keeps the context for each call minimal and highly relevant.
-   **Structured I/O:** By forcing the LLM to read and write JSON, we remove ambiguity. The system is not parsing English prose to figure out what to do next. This makes the system more reliable and predictable.
-   **Stateful Orchestrator, Stateless Model:** The intelligence and memory are in our Python code (the Orchestrator and Working Memory). The expensive, slow part (the LLM) is treated as a stateless function callâ€”a tool that is picked up, used for a specific job, and put down. This is the most efficient way to use a service like Groq.